{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from DataPreprocessing import DataPreprocessing\n",
    "from TextCleaner import TextCleaner\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from attention import AttentionLayer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DataPreprocessing()\n",
    "cleaner = TextCleaner()\n",
    "\n",
    "data =  processor.load_pickle('DataSequences')\n",
    "\n",
    "x_tr, x_test, x_dev, y_tr, y_test, y_dev = data[0],data[1],data[2],data[3],data[4],data[5]\n",
    "\n",
    "loaded_data = processor.load_pickle('TokenizerData')\n",
    "\n",
    "x_tokenizer, y_tokenizer, x_vocab_size,y_vocab_size, input_word_index,target_word_index, reversed_input_word_index, reversed_target_word_index, max_length_text, max_length_summary = loaded_data[0],loaded_data[1], loaded_data[2],loaded_data[3],loaded_data[4],loaded_data[5],loaded_data[6],loaded_data[7],loaded_data[8],loaded_data[9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction():\n",
    "    \n",
    "    def load_model(self,model_filename, model_weights_filename):\n",
    "        with open(model_filename, 'r', encoding='utf8') as f:\n",
    "            model = model_from_json(f.read(), custom_objects={'AttentionLayer': AttentionLayer})\n",
    "        model.load_weights(model_weights_filename)\n",
    "        return model\n",
    "        \n",
    "    def decode_sequence(self, input_seq, encoder_model, decoder_model):\n",
    "        encoder_outputs, h0, c0 = encoder_model.predict(input_seq)\n",
    "\n",
    "        # First word to be passed to the decoder \n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0,0] = target_word_index['sostok']\n",
    "\n",
    "        decoded_sentence = ''\n",
    "        stop_condition = False\n",
    "\n",
    "        while not stop_condition:\n",
    "\n",
    "            output_tokens, h, c = decoder_model.predict([target_seq] + [encoder_outputs,h0, c0])\n",
    "\n",
    "            # Sample output tokens\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_word = reversed_target_word_index[sampled_token_index]\n",
    "\n",
    "            if(sampled_word!='eostok'):\n",
    "                decoded_sentence += sampled_word + ' '\n",
    "\n",
    "            if (sampled_word == 'eostok' or (len(decoded_sentence.split()) + 1) > max_length_summary):\n",
    "                stop_condition = True\n",
    "\n",
    "            target_seq = np.zeros((1,1))\n",
    "            target_seq[0,0] = sampled_token_index\n",
    "\n",
    "            h0, c0 = h,c\n",
    "\n",
    "        return decoded_sentence\n",
    "    \n",
    "    def seqtotext(self, input_seq):\n",
    "        text = ''\n",
    "        for i in input_seq:\n",
    "            if i != 0:\n",
    "                text += reversed_input_word_index[i]+ ' '\n",
    "\n",
    "        return text\n",
    "    \n",
    "    def seqtosummary(self, input_seq):\n",
    "        summary = ''\n",
    "        for i in input_seq:\n",
    "            if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "                summary=summary+reversed_target_word_index[i]+' '\n",
    "        return summary\n",
    "    \n",
    "    def generated_summaries(self,index,encoder_model,decoder_model):\n",
    "        \"\"\"Generates 'index' number of summaries.\"\"\"\n",
    "        for i in range(0,index):\n",
    "            print(\"Original summary:\",self.seqtosummary(y_tr[i]))\n",
    "            print(\"Predicted summary:\",self.decode_sequence(x_tr[i].reshape(1,max_length_text),encoder_model,decoder_model))\n",
    "            print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
